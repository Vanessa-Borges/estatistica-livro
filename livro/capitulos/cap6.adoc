== Principais Distribuições Discretas

(((Distribuição)))

Aqui apresentaremos as principais distribuições de variáveis aleatórias discretas, ou seja, 
apresentaremos a função de probabilidade de algumas variáveis aleatórias importantes.

Além disso, apresentaremos algumas propriedades dessas variáveis aleatóriais, tais como
esperança e variância.

O objetivo dessa seção é que o estudante saiba reconhecer qual distribuição utilizar em 
cada situação. 

=== A Distribuição Bernoulli

(((Distribuição, Bernoulli)))

A primeira e mais simples distribuição é a distribuição Bernoulli. É a distribuição de uma 
variável aleatória que só pode assumir dois valores: 0 e 1.

Esta distribuição é bastante útil, pois normalmente usa-se a interpretação do resultado
1 como _sucesso_ e 0 como _fracasso_.  Mais precisamente, temos a

Definição: Variável Aleatória Seguindo Distribuição Bernoulli::
+
--
Seja latexmath:[$X$] uma variável aleatória discreta tomando os valores latexmath:[$0,1$]. 
Seja latexmath:[$p$], a probabilidade de latexmath:[$X$] assumir o valor 1, isto é,
seja latexmath:[$P(X=1)=p$]. Então, pela probabilidade do complementar, segue que
latexmath:[$P(X=0) = 1-p$]. Podemos escrever de forma compacta a função de probabilidade
de latexmath:[$X$] como
[latexmath]
++++
\[ P(X=i) = p^i (1-p)^{1-i},\quad i=0,1.\]
++++
Se latexmath:[$X$] satisfaz a definição acima dizemos que latexmath:[$X$] segue 
distribuição de Bernoulli com parâmetro latexmath:[$p$], e denotamos
latexmath:[$X\sim Ber(p)$]. 
--

Esperança::
+
--
Seja latexmath:[$X\sim Ber(p)$], então
[latexmath]
++++
\[E(X) = 0\cdot P(X=0) + 1\cdot P(X=1) = p.\]
++++
--

TIP: Observe que como latexmath:[$X$] só assume valor latexmath:[$0$] ou latexmath:[$1$], temos que 
latexmath:[$X = X^2$], e portanto, latexmath:[$E(X) = E(X^2)$].

Variância::
+
--
Seja latexmath:[$X\sim Ber(p)$], então
[latexmath]
++++
\[
Var(X) = E(X^2) - (E(X))^2 = E(X) - (E(X))^2 = p-p^2 = p(1-p).\]
++++
--

.Onde surge o uso da distribuição Bernoulli
====
A distribuição Bernoulli aparece naturalmente em várias situações. Alguns exemplos incluem:

* Lançamento de moedas;
* Encontrar produtos perfeitos ou defeituosos;
* Ganhar ou perder um sorteio.
====

=== A Distribuição Binomial

(((Distribuição, Binomial)))

A melhor maneira de ilustrar a distribuição binomial é com o seguinte exemplo:

.Exemplo de distribuição binomial
====
Suponha que temos uma urna com um certo número de bolas, donde com probabilidade
latexmath:[$p$] retiramos bolas azuis e com probabilidade latexmath:[$1-p$]
retiramos bolas vermelhas, se a retirada for ao acaso. Suponha que então
que latexmath:[$n$] bolas são retiradas *com reposição* (ou seja,
a probabilidade de tirar uma bola azul, não muda após as retiradas). 
Se latexmath:[$X$] é a variável aleatória dada pelo número de bolas azuis
que foram retiradas entre as latexmath:[$n$] bolas, dizemos que 
latexmath:[$X$] segue distribuição binomial com parâmetros latexmath:[$n$] 
e latexmath:[$p$]. 
====

[IMPORTANT]
====
Olhando para o exemplo anterior é possível observar que podemos pensar
numa distribuição binomial como uma distribuição que surge de 
latexmath:[$n$] distribuições de Bernoulli. De fato, se latexmath:[$X_i$]
é a variável aleatória que é igual a 1 se a _i_-ésima bola retirada foi
azul, e zero caso contrário, temos que latexmath:[$X_i \sim Ber(p)$]. 
Observe que como as retiradas das bolas são independentes, as variáveis
aleatórias latexmath:[$X_i$] são independentes. 

Desta forma, é fácil ver que o valor de latexmath:[$X$] é dado pela soma
latexmath:[$\displaystyle\sum_{i=1}^n X_i$]. Pois teremos retirado 
latexmath:[$k$] bolas azuis se, e somente se, tiver latexmath:[$k$]
variáveis aleatórias latexmath:[$X_i$] sendo iguais a 1.

Desta forma, podemos (e *devemos*) interpretar uma variável aleatória
seguindo distribuição binomial
como soma de latexmath:[$n$] variáveis aleatórias independentes
seguindo distribuição Bernoulli.
====

Vamos agora calcular a probabilidade em questão.

Note que para termos latexmath:[$k$] bolas azuis entre latexmath:[$n$] bolas
retiradas, devemos  ter exatamente latexmath:[$n-k$] bolas vermelhas. 
Como as retiradas de bolas são independentes, e a probabilidade de se 
obter uma bola azul é latexmath:[$p$], segue que a probabilidade
de termos latexmath:[$k$] bolas azuis e latexmath:[$n-k$] bolas vermelhas
é latexmath:[$p^k(1-p)^{n-k}$]. 

Para concluirmos o cálculo da probabilidade,
devemos calcular de quantas formas podemos retirar latexmath:[$k$] bolas
azuis e latexmath:[$n-k$] bolas vermelhas, se retiramos um total de 
latexmath:[$n$] bolas.

Esta quantidade é dada pelo número de subconjuntos de latexmath:[$k$] 
elementos em um conjunto com latexmath:[$n$] elementos. Para entender
esta conta, podemos pensar que temos um conjunto com latexmath:[$n$] 
bolas brancas. Tomando um subconjunto com latexmath:[$k$] elementos,
é a mesma coisa que retirar latexmath:[$k$] bolas. Então
pintamos essas latexmath:[$k$] bolas retiradas de azul, e as bolas
restantes pintamos de vermelho. Desta forma, temos uma maneira de 
retirar latexmath:[$k$] bolas azuis entre um total de latexmath:[$n$]
bolas retiradas. Assim, vemos que quando olhamos para todos os 
subconjunto de latexmath:[$k$] elementos, estamos olhando para
todas as formas de retirarmos latexmath:[$k$] bolas azuis 
entre latexmath:[$n$] bolas disponíveis.

Finalmente, o número de subconjuntos de latexmath:[$k$] elementos
de um conjunto com latexmath:[$n$] elementos é dado por
latexmath:[${n\choose k}$]. Portanto, temos que se latexmath:[$X$]
é a variável aleatória dada pelo número de bolas azuis retiradas
após retirarmos latexmath:[$n$] bolas, temos que
[latexmath]
++++
\[P(X=k) = {n \choose k} p^k (1-p)^{n-k},\quad k=0,\ldots, n.\]
++++

Esta é a função de probabilidade de uma distribuição binomial. Portanto, podemos fornecer
a seguinte

Definição: Variável Aleatória Seguindo Distribuição Binomial::
+
--
Seja latexmath:[$X$] uma variável aleatória dada pelo número de sucessos em latexmath:[$n$] 
ensaios de Bernoulli, ou seja, o número de sucessos obtidos em latexmath:[$n$]
variáveis aleatórias de Bernoulli independentes. Então, dizemos que latexmath:[$X$]
segue distribuição binomial, denotamos por latexmath:[$X\sim Bin(n,p)$], e sua função de probabilidade é dada por
[latexmath]
++++
\[P(X=k) = {n \choose k} p^k (1-p)^{n-k},\quad k=0,\ldots, n.\]
++++
--

É importante verificar que a nossa conta está correta, e que, de fato, a função de probabilidade
dada acima tem soma total igual a 1. Isto segue diretamente do binômio de Newton:

[latexmath]
++++
\[\sum_{k=0}^n P(X=k) = \sum_{k=0}^n {n \choose k} p^k (1-p)^{n-k} = (p+1-p)^n = 1.\]
++++


Esperança:: 
+
--
[latexmath]
++++
\[
\begin{array}{lll}
E(X) &=& \displaystyle\sum_{k=0}^n k {n\choose k} p^k (1-p)^{n-k} \\
&=& \displaystyle\sum_{k=1}^n k\frac{n!}{k!(n-k)!}p^k(1-p)^{n-k}\\
&=& \displaystyle\sum_{k=1}^n \frac{n!}{(k-1)!(n-k)!}p^k(1-p)^{n-k}.
\end{array}
\]
++++
Faça agora a mudança de variável latexmath:[$m=k-1$]. Isto 
implica latexmath:[$k=m+1$], e portanto, continuando,
[latexmath]
++++
\[
\begin{array}{lll}
E(X) &=& \displaystyle\sum_{k=1}^n \frac{n!}{(k-1)!(n-k)!}p^k(1-p)^{n-k}\\
&=& \displaystyle\sum_{m=0}^{n-1} \frac{n!}{m!(n-m-1)!}p^{m+1}(1-p)^{n-m-1}\\
&=& \displaystyle\sum_{m=0}^{n-1} \frac{n\cdot (n-1)!}{m!((n-1)-m)!}p\cdot p^{m}(1-p)^{(n-1)-m}\\
&=& np\displaystyle\sum_{m=0}^{n-1} \frac{(n-1)!}{m!(n-1-m)!} p^m(1-p)^{(n-1)-m}\\
&=& np (p+1-p)^{n-1}\\
&=& np.
\end{array}
\]
++++

Assim, latexmath:[$E(X) = np$]. 

[IMPORTANT]
====
Temos outra forma de calcular a esperança usando ensaios de Bernoulli.

Como mencionamos, se latexmath:[$X_i\sim Ber(p)$] são independentes para
latexmath:[$i=1,\ldots, n$], então, latexmath:[$\displaystyle\sum_{i=1}^n X_i \sim Bin(n,p)$].
Fazendo latexmath:[$X = \displaystyle\sum_{i=1}^n X_i$], temos que latexmath:[$X\sim Bin(n,p)$],
e usando a propriedade de soma de esperança, segue que
[latexmath]
++++
\[E(X) = E\Big(\sum_{i=1}^n X_i\Big) = \sum_{i=1}^n E(X_i) = \sum_{i=1}^n p = np,\]
++++
pois, como vimos na distribuição Bernoulli, latexmath:[$E(X_i) = p$]. 
====
--

Variância::
+
--
Vamos começar calculando latexmath:[$E(X^2)$]:
[latexmath]
++++
\[
\begin{array}{lll}
E(X^2) &=& \displaystyle\sum_{k=0}^n k^2 {n\choose k}p^k (1-p)^{n-k}\\
&=& \displaystyle\sum_{k=1}^n k(k-1 +1) {n\choose k}p^k (1-p)^{n-k}\\
&=& \displaystyle\sum_{k=2}^n k(k-1) {n\choose k}p^k (1-p)^{n-k} + \displaystyle\sum_{k=1}^n k {n\choose k}p^k (1-p)^{n-k}\\
&=& \displaystyle\sum_{k=2}^n k(k-1) {n\choose k}p^k (1-p)^{n-k} + E(X)\\
&=& \displaystyle\sum_{k=2}^n k(k-1) {n\choose k}p^k (1-p)^{n-k} + np.
\end{array}
\]
++++
Vamos então calcular o último somatório do lado direito:
[latexmath]
++++
\[
\begin{array}{lll}
\displaystyle\sum_{k=2}^n k(k-1) {n\choose k}p^k (1-p)^{n-k} &=& \displaystyle\sum_{k=2}^n k(k-1) \frac{n!}{k!(n-k)!}p^k (1-p)^{n-k}\\
&=& \displaystyle\sum_{k=2}^n \frac{n!}{(k-2)!(n-k)!}p^k (1-p)^{n-k}.
\end{array}
\]
++++
Façamos agora a mudança de variável latexmath:[$m=k-2$], daí latexmath:[$k=m+2$]. Portanto,
[latexmath]
++++
\[
\begin{array}{lll}
\displaystyle\sum_{k=2}^n k(k-1) {n\choose k}p^k (1-p)^{n-k} &=& \displaystyle\sum_{m=0}^{n-2}  \frac{n!}{m!(n-2-m)!}p^{m+2} (1-p)^{n-2-m}\\
&=& \displaystyle\sum_{m=0}^{n-2}  n(n-1)\frac{(n-2)!}{m!(n-2-m)!}p^2\cdot p^{m} (1-p)^{n-2-m}\\
&=& n(n-1)p^2 \displaystyle\sum_{m=0}^{n-2}  \frac{(n-2)!}{m!(n-2-m)!}p^{m} (1-p)^{n-2-m}\\
&=& n(n-1)p^2 (p+1-p)^{n-2}\\
&=& n(n-1)p^2.
\end{array}
\]
++++

Assim, juntando as contas, temos que
[latexmath]
++++
\[
E(X^2) = n(n-1)p^2 + np = (np)^2 + np - np^2 = (np)^2 + np(1-p). 
\]
++++

Finalmente, obtemos
[latexmath]
++++
\[
\begin{array}{lll}
Var(X) &=& E(X^2) - (E(X))^2 = (np)^2 + np(1-p)-(np)^2\\
&=& np(1-p).
\end{array}
\]
++++
--

Exercício::
+
--
Um servidor de um jogo online possui 20 _slots_ disponíveis, ou seja,
aceita até 20 jogadores simultaneamente. A probabilidade, em qualquer
hora do dia, de que um desses _slots_ esteja disponível é de 40%, 
e que a disponibilidade dos _slots_ são independentes.
Qual a probabilidade de um par de amigos encontrarem dois slots disponíveis?
--

_Solução_::
+
--
Seja latexmath:[$X$] o número de _slots_ disponíveis no jogo. Sabemos,
pela definição do problema que latexmath:[$X\sim Bin(20,0.4)$].
Queremos calcular latexmath:[$P(X\geq 2)$]. 

Note que latexmath:[$P(X\geq 2) = 1 - P(X=1) - P(X=0)$]. Daí,
[latexmath]
++++
\[
P(X=0) = {20 \choose 0} (0.4)^0(0.6)^{20} = (0.6)^{20};
\]
++++
e
[latexmath]
++++
\[
P(X=1) = {20\choose 1} 0.4(0.6)^{19} = 20\cdot 0.4 (0.6)^{19} = 8\cdot (0.6)^{19}.
\]
++++
Desta forma,
[latexmath]
++++
\[
P(X\geq 2) = 1-(0.6)^{20} - 8(0.6)^{19}.
\]
++++
--

NOTE: Observe que a hipótese de independência no exemplo acima não é realista, porém
é necessária para ser possível trabalhar matematicamente. Caso contrário seria
muito complicado. Suposições desta natureza para facilitar a resolução prática
de problemas são muito comuns.


=== A Distribuição Geométrica
(((Distribuição, Geométrica)))

Suponha que uma pessoa tem uma moeda que pode ser desonesta, 
ou seja, assume cara com probabilidade latexmath:[$p$], e coroa com probabilidade
latexmath:[$1-p$]. Vamos agora considerar o experimento aleatório:
lançar esta moeda sucessivamente até obter cara.

Qual a probabilidade da cara ser obtida no lançamento número latexmath:[$k$]?
Ou colocando numa forma mais matemática, se latexmath:[$X$] é a variável
aleatória dada pelo número do lançamento no qual a cara foi obtida, qual
é a probabilidade latexmath:[$P(X=k)$]?

A resposta é simples. Para obtermos cara no lançamento número latexmath:[$k$],
esta pessoa terá que ter obtido coroa em todos os latexmath:[$k-1$] lançamentos
anteriores e ter obtido cara exatamente no latexmath:[$k$]-ésimo lançamento. 
Como os lançamentos das moedas são independentes, temos que esta probabilidade
é
[latexmath]
++++
\[
P(X=k) = p(1-p)^{k-1},\quad k=1,2,\ldots.
\]
++++

Essa variável aleatória latexmath:[$X$] é uma variável aleatória que segue distribuição geométrica. 
Mais precisamente,

Definição: Variável Aleatória Seguindo Distribuição Geométrica::
+
--
Sejam latexmath:[$X_1,X_2,X_3,\ldots$] variáveis aleatórias independentes seguindo distribuição
Bernoulli com parâmetro latexmath:[$p$]. Seja latexmath:[$X$] a variável aleatória dada pela
ocorrência do primeiro sucesso, ou seja, o menor índice latexmath:[$i$], tal que latexmath:[$X_i$]
teve sucesso. Então, dizemos que latexmath:[$X$] segue distribuição geométrica com parâmetro latexmath:[$p$],
e denotamos latexmath:[$X\sim G(p)$]. A função de probabilidade de latexmath:[$X$] é dada por
[latexmath]
++++
\[
P(X=k) = p(1-p)^{k-1},\quad k=1,2,\ldots.
\]
++++
--

Primeiro vamos observar que a nossa conta está correta e, de fato, a função descrita acima é uma função de probabilidade.
Temos claramente que latexmath:[$p(1-p)^{k-1}\geq 0$], e pela soma dos termos de uma progressão *geométrica*, temos
[latexmath]
++++
\[
\sum_{k=1}^\infty p(1-p)^{k-1} = p\sum_{k=1}^\infty (1-p)^{k-1} = p\frac{1}{1-(1-p)} = \frac{p}{p} = 1.
\]
++++

Antes de calcularmos a esperança e variância da distribuição geométrica utilizaremos os seguintes resultados
sobre séries geométricas e suas derivadas:

* Definindo a função latexmath:[$f(r) = \sum_{k=0}^\infty r^k$], temos que ela converge para 
latexmath:[$0\leq r < 1$], e vale a igualdade
[latexmath]
++++
\[
f(r) = \sum_{k=0}^\infty r^k = \frac{1}{1-r};
\]
++++

* Temos que para todo latexmath:[$0\leq r < 1$], latexmath:[$f$] é infinitamente diferenciável, e sua derivada, para
latexmath:[$0\leq r <1$] é dada por
[latexmath]
++++
\[
f'(r) = \sum_{k=1}^\infty k r^{k-1} = \frac{1}{(1-r)^2};
\]
++++

* Para latexmath:[$0\leq r <1$] a segunda derivada de latexmath:[$f$] é dada por
[latexmath]
++++
\[
f''(r) = \sum_{k=2}^\infty k(k-1)r^{k-2} = \frac{2}{(1-r)^3}.
\]
++++


Esperança::
+
--
Temos que
[latexmath]
++++
\[
\begin{array}{lll}
E(X)&=& \displaystyle\sum_{k=1}^\infty kp(1-p)^{k-1}\\
&=& p \displaystyle\sum_{k=1}^\infty k (1-p)^{k-1}\\
&=& p \displaystyle\frac{1}{(1-(1-p))^2}\\
&=& p \displaystyle\frac{1}{p^2}\\
&=&\displaystyle\frac{1}{p}.
\end{array}
\]
++++
--


Variância::
+
--

Para encontrar latexmath:[$E(X^2)$] vamos calcular primeiro
latexmath:[$E[X(X-1)\]$], usando a fórmula da segunda derivada
da série geométrica:
[latexmath]
++++
\[
\begin{array}{lll}
E[X(X-1)] &=& \displaystyle\sum_{k=2}^\infty k(k-1) p(1-p)^{k-1}\\
&=& p(1-p) \displaystyle\sum_{k=2}^\infty k(k-1) (1-p)^{k-2}\\
&=& p (1-p) \displaystyle\frac{2}{(1-(1-p))^3}\\
&=& p (1-p) \displaystyle\frac{2}{p^3}\\
&=& \displaystyle\frac{2(1-p)}{p^2}.
\end{array}
\]
++++

Assim, segue que:
[latexmath]
++++
\[
E[X(X-1)] = E(X^2-X) = E(X^2) - E(X) = E(X^2) - \frac{1}{p}.
\]
++++
Ou seja, 
[latexmath]
++++
\[
E(X^2) = E(X^2) + \frac{1}{p} = \frac{2(1-p)}{p^2} + \frac{1}{p} = \frac{2-2p}{p^2}+\frac{p}{p^2} = \frac{2-p}{p^2}.
\]
++++
Finalmente,
[latexmath]
++++
\[
Var(X) = E(X^2) - (E(X))^2 = \frac{2-p}{p^2} - \frac{1}{p^2} = \frac{1-p}{p^2}.
\]
++++
--

(((Distribuição, Geométrica, Perda de memória)))

Perda de Memória::
+
--
Suponha que João está lançando moedas até o resultado sair cara. Suponha que esta João já lançou a moeda 12 vezes, e ainda não saiu cara,
isto significa que a probabilidade do resultado sair cara no próximo lançamento será maior do que era 12 jogadas atrás?

A resposta é não. Não importa o quanto tempo João tenha esperado, a probabilidade do próximo lançamento sempre será 1/2. Esta propriedade da
distribuição geométrica é chamada de _perda de memória_.

Mais precisamente, seja latexmath:[$X$] uma variável aleatória seguindo distribuição Geométrica com parâmetro latexmath:[$p$].
Então, temos que para todo par de inteiros positivos, latexmath:[$m,n$], vale
[latexmath]
++++
\[
P(X>m+n|X>m) = P(X>n).
\]
++++

De fato, temos que
[latexmath]
++++
\[
P(X>m+n|X>m) = \frac{P(X>m+n,X>m)}{P(X>m)} = \frac{P(X>m+n)}{P(X>m)},
\]
++++
no entanto, usando a fórmula da soma dos termos de uma progressão geométrica infinita, temos
[latexmath]
++++
\[
P(X>m+n) = \sum_{k=m+n+1}^\infty p(1-p)^{k-1} = \frac{p(1-p)^{m+n}}{1-(1-p)} = (1-p)^{m+n}.
\]
++++
Analogamente, latexmath:[$P(X>m) = (1-p)^m$]. Logo,

[latexmath]
++++
\[
P(X>m+n|X>m) = \frac{P(X>m+n)}{P(X>m)} = \frac{(1-p)^{m+n}}{(1-p)^m} = (1-p)^n = P(X>n).
\]
++++

Isto prova a perda de memória. Observe que aqui, na realidade, 
mostra mais do que falamos. Não só diz que a próxima probabilidade não muda,
mas essencialmente diz o seguinte: se João já esperou um certo 
tempo latexmath:[$m$] para sair cara, e a cara ainda não saiu,
as probabilidades de sair cara dali para frente são as mesmas 
de como se ele tivesse começado a lançar naquele momento. Ou seja,
a distribuiçã geométrica ``esquece'' todo o passado que já foi executado.
--



=== A Distribuição Pascal (ou Binomial Negativa)

(((Distribuição, Pascal)))
(((Distribuição, Binomial Negativa)))

==== Generalização do Binômio de Newton

Antes de definirmos esta distribuição, vamos rever rapidamente um pouco de teoria matemática
presente em cursos de cálculo.

(((Série de Taylor)))

(((Função, Analítica)))

Existe uma classe de funções reais, tais que a seguinte fórmula, conhecida como
_expansão em série de Taylor_, é verdade

[latexmath]
++++
\[
f(x) = f(a) + f'(a)(x-a) + \frac{f''(a)}{2} (x-a)^2 + \cdots = \sum_{k=0}^\infty \frac{f^{(k)}(a)}{k!} (x-a)^k,
\]
++++

onde latexmath:[$f^{(k)}(a)$] denota a latexmath:[$k$]-ésima derivada de latexmath:[$f$] no ponto latexmath:[$a$],
e latexmath:[$f:I\to\mathbb{R}$], onde latexmath:[$I\subset\mathbb{R}$] é um intervalo aberto.

As funções tais que essa expansão é válida são conhecidas como _funções analíticas_. 

IMPORTANT: Conhecemos várias funções analíticas: a função exponencial; seno; co-seno; logaritmo; poliônimos e frações de polinômios.

Um caso particular importante é dado pelas funções do tipo latexmath:[$f(x) = (1-x)^{-r-1} = \frac{1}{(1-x)^{r+1}}$], onde latexmath:[$r$]
é um número natural. Como latexmath:[$f$] é fração de polinômios, temos que latexmath:[$f$] é analítica. Assim, considerando o 
ponto latexmath:[$a=0$], temos
[latexmath]
++++
\[
f(x) = (1-x)^{-r-1};\quad f'(x) = -(-r-1)(1-x)^{-r-2};\quad f''(x) = -(-r-2)(-r-1)(1-x)^{-r-3},\ldots,
\]
++++
e em geral, temos
[latexmath]
++++
\[
f^{(k)}(x) = -(-r-k)(-r-(k-1))\cdots(-r-1)(1-x)^{-r-k-1}.
\]
++++

(((Coeficiente Binomial Generalizado)))

Definindo o _coeficiente binomial generalizado_ como
[latexmath]
++++
\[
{-r \choose k} = \frac{(-r)(-r-1)\ldots (-r-k+1)}{k!},\quad k=0,1,2,\ldots,
\]
++++
podemos escrever
[latexmath]
++++
\[
f^{(k)}(x) = (-1)^k k! {-r-1\choose k} (1-x)^{-r-k-1}.
\]
++++

Aplicando no ponto latexmath:[$a=0$], temos 

[latexmath]
++++
\[
f^{(k)}(0) = (-1)^k k! {-r-1\choose k},
\]
++++

por sua vez, usando na série de Taylor, obtemos, 

[latexmath]
++++
\[
(1-x)^{-r-1} = f(x) = \sum_{k=0}^\infty \frac{f^{(k)}(0)}{k!} x^k = \sum_{k=0}^\infty (-1)^k {-r-1\choose k} x^k = \sum_{k=0}^\infty  {-r-1\choose k} (-x)^k.
\]
++++

(((Binômio de Newton, Generalizado)))

Assim, temos o binômio de Newton generalizado:

[latexmath]
++++
\[
(1-x)^{-r-1} = \sum_{k=0}^\infty  {-r-1\choose k} (-x)^k.
\]
++++

Observe que vale também a igualdade:

[latexmath]
++++
\[
\begin{array}{lll}
\displaystyle{r+k\choose k} &=& \displaystyle\frac{(r+k)(r+k-1)\cdots (r+1)r}{k!}\\
&=& \displaystyle(-1)^k \frac{(-r-k)(-r-(k-1))\cdots (-r-1)(-r)}{k!} = (-1)^k {-r-1 \choose k}.
\end{array}
\]
++++

Daí, vale também a fórmula do binômio de Newton generalizado:

[latexmath]
++++
\[
(1-x)^{-r-1} = \sum_{k=0}^\infty {r+k\choose k} x^k.
\]
++++

==== Distribuição Pascal

A distribuição de Pascal (ou Binomial Negativa) é uma generalização natural da distribuição geométrica. Para entendermos melhor
esta distribuição, voltemos ao exemplo do lançamento de moedas. 

Se uma pessoa tem uma moeda que pode ser desonesta, ou seja, assume cara com probabilidade latexmath:[$p$], e coroa com probabilidade
latexmath:[$1-p$]. Suponha que temos o seguinte experimento aleatório: lançar uma moeda sucessivamente até obter latexmath:[$r$] caras.

Qual a probabilidade da latexmath:[$r$]-ésima cara ser obtida no lançamento latexmath:[$k$]? Ou, escrevendo de uma maneira
matematicamente mais precisa, se latexmath:[$X$] denota a variável aleatória dada pelo número do lançamento pelo qual a 
latexmath:[$r$]-ésima cara foi obtida, qual é a probabilidade latexmath:[$P(X=k)$]?

Vamos calcular essa probabilidade por partes. Comece notando que latexmath:[$X=k$], se e somente se, no latexmath:[$k$]-ésimo
lançamento o resultado foi cara e nos latexmath:[$k-1$] lançamentos anteriores, obtemos latexmath:[$r-1$] caras. O número de 
formas de isso acontecer é simples: escolher latexmath:[$r-1$] resultados para sair cara, entre latexmath:[$k-1$] resultados possíveis,
ou seja, temos latexmath:[${k-1\choose r-1}$] possibilidades. 

Finalmente, como
em um total de latexmath:[$k$] lançamentos, saíram latexmath:[$r$] caras e latexmath:[$k-r$] coroas, e temos latexmath:[${k-1 \choose r-1}$]
possibilidades, a probabilidade é dada por
[latexmath]
++++
\[
P(X=k) = {k-1\choose r-1} p^r(1-p)^{k-r},\quad k=r,r+1,\ldots,
\]
++++
onde latexmath:[$k\geq r$], pois para obter latexmath:[$r$] caras, temos que no mínimo ter latexmath:[$k$] lançamentos.

IMPORTANT: Observe que se latexmath:[$r=1$], temos que latexmath:[$X$] segue uma distribuição geométrica com parâmetro 
latexmath:[$p$].

Mais precisamente,

Definição: Variável Aleatória Seguindo Distribuição Pascal::
+
--
Sejam latexmath:[$X_1,X_2,\ldots$] variáveis aleatórias independentes seguindo distribuição Bernoulli com parâmetro 
latexmath:[$p$]. Seja latexmath:[$X$] a variável aleatória dada pela ocorrência do latexmath:[$r$]-ésimo sucesso, ou
seja, o índice latexmath:[$i$], tal que latexmath:[$X_i$] é o latexmath:[$r$]-ésimo sucesso. Então, dizemos que 
latexmath:[$X$] segue distribuição Pascal (ou binomial negativa) com parâmetros latexmath:[$r$] e latexmath:[$p$],
e denotamos latexmath:[$X\sim Pas(r,p)$]. A função de probabilidade de latexmath:[$X$] é
[latexmath]
++++
\[
P(X=k) = {k-1\choose r-1} p^r(1-p)^{k-r},\quad k=r,r+1,\ldots,
\]
++++
--

Vamos começar mostrando que a função acima é, de fato, uma função de probabilidade. Claramente, latexmath:[${k-1\choose r-1} p^r(1-p)^{k-r}\geq 0$],
e, temos ainda que usando a mudança de variável latexmath:[$j=k-r$], 
[latexmath]
++++
\[
\begin{array}{lll}
\displaystyle\sum_{k=r}^\infty {k-1\choose r-1} p^r(1-p)^{k-r} &=& \displaystyle\sum_{j=0}^\infty {j+r-1\choose r-1} p^r (1-p)^j\\
&=& p^r \displaystyle\sum_{j=0}^\infty {j+r-1 \choose j} (1-p)^j\\
&=& p^r \displaystyle\frac{1}{(1-(1-p))^r}\\
&=& p^r\displaystyle\frac{1}{p^r}\\
&=& 1,
\end{array}
\]
++++

onde usamos o binômio de Newton generalizado e usamos que 
[latexmath]
++++
\[
{j+r-1\choose r-1} =\frac{(j+r-1)!}{(r-1)!j!} =  {j+r-1\choose j}.
\]
++++

[NOTE]
====
A distribuição de Pascal, ou Binomial Negativa, recebe o nome de binomial negativa, por utilizar o binômio de Newton
generalizado (com expoente negativo) para calcular sua esperança e variância, assim como para mostrar que a 
soma das probabilidades é igual a 1.
====

[IMPORTANT]
====
Existe uma caracterização da distribuição Pascal em termos de soma de variáveis aleatórias
seguindo distribuição geométrica:
sejam latexmath:[$X_1,X_2,\ldots,X_r$] variáveis aleatórias independentes seguindo distribuição
Geométrica com parâmetro latexmath:[$p$]. Assim, definindo latexmath:[$X=\sum_{k=1}^r X_k$], temos
que latexmath:[$X$] segue distribuição Pascal com parâmetros latexmath:[$r$] e latexmath:[$p$]. 

A intuição é que para termos a ``posição'' do latexmath:[$r$]-ésimo sucesso, contabilizamos a posição
do primeiro sucesso com a variável latexmath:[$X_1$], adicionamos a variável latexmath:[$X_2$]
para obter a posição do segundo sucesso, latexmath:[$\ldots,$],
adicionamos a variável latexmath:[$X_r$] para obter a posição do latexmath:[$r$]-ésimo sucesso. Ou seja,
cada variável geométrica latexmath:[$X_i$] representa o tempo que temos que esperar
entre os sucessos, até a obtenção de um sucesso.
====

Esperança::
+
--

Temos que, fazendo a mudança latexmath:[$j=k-r$], 

[latexmath]
++++
\[
\begin{array}{lll}
\displaystyle E(X) &=& \displaystyle\sum_{k=r}^\infty k {k-1 \choose r-1} p^r (1-p)^{k-r} \\
&=& \displaystyle\sum_{j=0}^\infty (j+r) {j+r-1\choose r-1} p^r (1-p)^j\\
&=& p^r \displaystyle\sum_{j=0}^\infty (j+r)\frac{(j+r-1)!}{(r-1)!j!} (1-p)^j\\
&=& p^r \displaystyle\sum_{j=0}^\infty \frac{(j+r)!}{(r-1)!j!} (1-p)^j\\
&=& p^r \displaystyle\sum_{j=0}^\infty r \frac{(j+r)!}{r!j!} (1-p)^j\\
&=& p^r \displaystyle\sum_{j=0}^\infty r {j+r\choose j} (1-p)^j\\
&=& r p^r \displaystyle\sum_{j=0}^\infty {j+r\choose j} (1-p)^j\\
&=& r p^r \displaystyle\frac{1}{(1-(1-p))^{r+1}}\\
&=& \displaystyle\frac{r}{p}.
\end{array}
\]
++++

[IMPORTANT]
====
Vale a pena notar que utilizando a caracterização de latexmath:[$X$] como soma de variáveis
aleatórias independentes seguindo distribuição geométrica, temos que
[latexmath]
++++
\[
X = \sum_{i=1}^r X_i,
\]
++++
onde latexmath:[$X_i\sim G(p)$]. Daí,
[latexmath]
++++
\[
E(X) = E\Big( \sum_{i=1}^r X_i \Big) = \sum_{i=1}^r E(X_i) = \sum_{i=1}^r \frac{1}{p} = \frac{r}{p}.
\]
++++
====
--

Variância::
+
--
Vamos começar calculando latexmath:[$E[X(X+1)\]$]:
[latexmath]
++++
\[
\begin{array}{lll}
\displaystyle E[X(X+1)] &=& \displaystyle\sum_{k=r}^\infty k(k+1) {k-1 \choose r-1} p^r (1-p)^{k-r} \\
&=& \displaystyle\sum_{j=0}^\infty (j+r+1)(j+r) {j+r-1\choose r-1} p^r (1-p)^j\\
&=& p^r \displaystyle\sum_{j=0}^\infty (j+r+1)(j+r)\frac{(j+r-1)!}{(r-1)!j!} (1-p)^j\\
&=& p^r \displaystyle\sum_{j=0}^\infty \frac{(j+r+1)!}{(r-1)!j!} (1-p)^j\\
&=& p^r \displaystyle\sum_{j=0}^\infty r(r+1) \frac{(j+r+1)!}{(r+1)!j!} (1-p)^j\\
&=& p^r \displaystyle\sum_{j=0}^\infty r(r+1) {j+r+1\choose j} (1-p)^j\\
&=& r(r+1) p^r \displaystyle\sum_{j=0}^\infty {j+r+1\choose j} (1-p)^j\\
&=& r(r+1) p^r \displaystyle\frac{1}{(1-(1-p))^{r+2}}\\
&=& \displaystyle\frac{r(r+1)}{p^2}.
\end{array}
\]
++++

Portanto, temos que latexmath:[$E[X(X+1)\] = E(X^2+X) = E(X^2)+E(X)$]. Como latexmath:[$E(X) = r/p$] e 
latexmath:[$E[X(X+1)\] = r(r+1)/p^2$], temos que
[latexmath]
++++
\[
E(X^2) = \frac{r(r+1)}{p^2} - \frac{r}{p} = \frac{r^2 + r - rp}{p^2}.
\]
++++
Finalmente, a variância é dada por
[latexmath]
++++
\[
Var(X) = E(X^2) - (E(X))^2 = \frac{r^2+r-rp}{p^2} - \frac{r^2}{p^2} = \frac{r-rp}{p^2} = \frac{r(1-p)}{p^2}.
\]
++++

--

=== Distribuição Hipergeométrica

Assim como na distribuição binomial, vamos ilustrar a distribuição hipergeométrica com um exemplo:

.Exemplo de distribuição hipergeométrica
====
Suponha que temos uma urna com latexmath:[$N$] bolas, das quais latexmath:[$n$] bolas são _azuis_, e 
latexmath:[$N-n$] bolas são _vermelhas_. Suponha que latexmath:[$m$] bolas foram retiradas aleatoriamente
da urna *sem reposição*. Se latexmath:[$X$] é a variável aleatória dada pelo número de bolas azuis
que foram retiradas entre as latexmath:[$m$] bolas, dizemos que latexmath:[$X$] segue distribuição
hipergeométrica com parâmetros latexmath:[$N,n,m$].
====

Vamos agora calcular a probabilidade em questão. 

Queremos calcular a probabilidade de termos latexmath:[$k$] bolas azuis. 
Note que temos latexmath:[$m$] retiradas de bolas, entre as quais queremos 
latexmath:[$k$] bolas azuis e latexmath:[$m-k$] bolas vermelhas. O
total de bolas azuis é latexmath:[$n$], então temos
latexmath:[${n\choose k}$] formas de selecionar estas bolas azuis
e como temos latexmath:[$N-n$] bolas vermelhas, temos latexmath:[${N-n\choose m-k}$]
formas de selecionar as bolas vermelhas. Como temos latexmath:[$N$] bolas
no total, e queremos selecionar latexmath:[$m$] bolas, temos
latexmath:[${N\choose m}$] formas de selecionar latexmath:[$m$] bolas. Portanto,
a probabilidade é dada por
[latexmath]
++++
\[
P(X=k) = \frac{{n\choose k}{N-n\choose m-k}}{{N\choose m}}.
\]
++++

Temos então a

(((Distribuição, Hipergeométrica)))

Definição: Variável Aleatória Seguindo Distribuição Hipergeométrica::
+
--
Suponha que temos latexmath:[$N$] objetos para selecionarmos.
Suponha que temos latexmath:[$n$] formas de obter uma seleção  ``boa'', 
e latexmath:[$N-n$] formas de obter uma seleção ``ruim''.
Suponha que tomemos  uma amostra de tamanho latexmath:[$m$], *sem reposição*,
e seja latexmath:[$X_i$] a variável aleatória que assume valor 1, se a 
latexmath:[$i$]-ésima seleção foi _boa_ e assume valor 0, se a latexmath:[$i$]-ésima
seleção foi _ruim_. Então se latexmath:[$X$] denota o número de seleções _boas_,
ou seja, se
[latexmath]
++++
\[
X = \sum_{i=1}^m X_i,
\]
++++
dizemos que latexmath:[$X$] segue distribuição hipergeométrica com parâmetros
latexmath:[$N,n, m$], denotamos por latexmath:[$X\sim HG(N,n,m)$], e sua
função de probabilidade é dada por
[latexmath]
++++
\[
P(X=k) = \frac{{n\choose k}{N-n\choose m-k}}{{N\choose m}},\quad k=0,\ldots, m.
\]
++++
--

Vamos mostrar que a função acima é uma função de probabilidade. Claramente, latexmath:[$\frac{{n\choose k}{N-m\choose m-k}}{{N\choose m}}\geq 0$].
Para mostrar que a soma sobre todos os valores de latexmath:[$k$] é igual a 1, vamos obter uma identidade de
coeficientes binomiais.

Considere o coeficiente de latexmath:[$x^m$] na expansão de latexmath:[$(1+x)^N$] em binômio de Newton. Este coeficiente
é dado por latexmath:[${N\choose m}$]. 

Por outro lado, sabemos que latexmath:[$(1+x)^N = (1+x)^n (1+x)^{N-n}$]. Vamos olhar então o coeficiente de
latexmath:[$x^m$] na expansão de latexmath:[$(1+x)^n (1+x)^{N-n}$], que é igual a latexmath:[${N\choose m}$].

Mas, observe que
[latexmath]
++++
\[
\begin{array}{lll}
\displaystyle (1+x)^n (1+x)^{N-n} &=& \displaystyle\Big( \sum_{i=0}^n {n\choose i} x^i\Big) \Big( \sum_{j=0}^{N-n} {N-n\choose j} x^j\Big)\\
&=& \displaystyle \sum_{i=0}^N \Big( \sum_{j=0}^i {n\choose j} {N-n\choose i-j} \Big) x^i. 
\end{array}
\]
++++

Assim, o coeficiente de latexmath:[$x^m$] na expansão de latexmath:[$(1+x)^n(1+x)^{N-n}$] é dado por
[latexmath]
++++
\[
\sum_{k=0}^m {n\choose k} {N-n\choose m-k}.
\]
++++

(((Identidade de Chu-Vandermonte)))

Portanto, notando que o coeficiente de latexmath:[$x^m$] na expansão de latexmath:[$(1+x)^n(1+x)^{N-n}$] é igual ao
coeficiente de latexmath:[$x^m$] na expansão de latexmath:[$(1+x)^N$], pois latexmath:[$(1+x)^N = (1+x)^n(1+x)^{N-n}$], 
chegamos à identidade de _Chu-Vandermonte_:

[latexmath]
++++
\[
{N\choose m} = \sum_{k=0}^m {n\choose k}{N-n\choose m-k}.
\]
++++

Dividindo ambos os lados por latexmath:[${N\choose m}$], temos

[latexmath]
++++
\[
\sum_{k=0}^m \frac{{n\choose k}{N-n\choose m-k}}{{N\choose m}} = 1.
\]
++++

Isto é o que queríamos provar, pois latexmath:[$P(X=k) = \frac{{n\choose k}{N-n\choose m-k}}{{N\choose m}}$].

Esperança::
+
--
Temos que
[latexmath]
++++
\[
\begin{array}{lll}
\displaystyle E(X) &=& \displaystyle \sum_{k=0}^m k \frac{{n\choose k}{N-n\choose m-k}}{{N\choose m}}\\
&=& \displaystyle \sum_{k=1}^m k \frac{{n\choose k}{N-n\choose m-k}}{{N\choose m}}\\
&=& \displaystyle \sum_{k=1}^m k {n\choose k} \frac{{N-n\choose m-k}}{{N\choose m}}\\
&=& \displaystyle \sum_{k=1}^m k \frac{n!}{k!(n-k)!} \frac{{N-n\choose m-k}}{{N\choose m}}\\
&=& \displaystyle \sum_{k=1}^m \frac{n!}{(k-1)!(n-k)!} \frac{{N-n\choose m-k}}{{N\choose m}}\\
&=& \displaystyle \sum_{k=1}^m n \frac{(n-1)!}{(k-1)!(n-k)!} \frac{{N-n\choose m-k}}{{N\choose m}}\\
&=& \displaystyle n \sum_{k=1}^m  {n-1 \choose k-1} \frac{{N-n\choose m-k}}{{N\choose m}}\\
&=& \displaystyle n \sum_{k=1}^m \frac{{n-1 \choose k-1}{N-n\choose m-k}}{{N\choose m}}\\
&=& \displaystyle n \sum_{k=1}^m \frac{{n-1 \choose k-1}{N-n\choose m-k}}{N/m {N-1 \choose m-1}}\\
&=& \displaystyle \frac{nm}{N} \sum_{k=1}^m \frac{{n-1 \choose k-1}{N-n\choose m-k}}{{N-1\choose m-1}}\\
&=& \displaystyle \frac{nm}{N},
\end{array}
\]
++++
onde na última igualdade utilizamos a identidade de Chu-Vandermonte com a terna latexmath:[$(N-1,n-1,m-1)$]. 

[NOTE]
====
Podemos também utilizar a caracterização de latexmath:[$X$] como a soma
[latexmath]
++++
\[
X = \sum_{i=1}^m X_i,
\]
++++
onde latexmath:[$X_i$] denota a variável aleatória que assume valor 1 se a latexmath:[$i$]-ésima seleção foi _boa_,
e assume valor 0 se a latexmath:[$i$]-ésima seleção foi _ruim_. 

Observe que temos latexmath:[$n$] seleções boas, entre um total de latexmath:[$N$] possibilidades, ou seja, 
para cada latexmath:[$i$], as variáveis latexmath:[$X_i$] possuem a mesma função de probabilidade:
[latexmath]
++++
\[
P(X_i =1 ) = \frac{n}{N},
\]
++++
daí, latexmath:[$E(X_i) = n/N$], e portanto,
[latexmath]
++++
\[
E(X) = E\Big(\sum_{i=1}^m X_i\Big) = \sum_{i=1}^m E(X_i) = \sum_{i=1}^m \frac{n}{N} = \frac{nm}{N}.
\]
++++
====
--

Variância::
+
--
Utilizando a mesma técnica da esperança é possível mostrar que 
[latexmath]
++++
\[
Var(X) = \frac{mn(N-n)(N-m)}{N^2(N-1)}.
\]
++++
--

=== Distribuição Poisson

(((Distribuição, Poisson)))

(((Lei dos eventos raros)))

Vamos começar motivando a definição da distribuição de Poisson por meio da aproximação
conhecida como _lei dos eventos raros_. Também é conhecida como aproximação da distribuição
binomial pela distribuição Poisson. 

Para tanto, considere o seguinte exemplo:

.Motivação para a distribuição de Poisson
====
Suponha que uma empresa tem uma linha telefônica dedicada exclusivamente a reclamações. 
Num período fixado de 4 horas (por exemplo 08:00 às 12:00) essa linha recebe em média 
500 ligações. Entretanto, essas ligações ocorrem aleatoriamente ao longo dessas 4 horas. Assim,
sabemos que ao longo dos dias, teremos uma quantidade média de 500 ligações ao final das 4 horas, mas não sabemos
em que momentos essas ligações são recebidas, nem o número exato de ligações recebidas em cada dia.

A pergunta que surge é: Qual a probabilidade de termos latexmath:[$k$] ligações no período de 4 horas no dia de hoje?


Responder a pergunta acima não é uma tarefa trivial, e essa resposta envolve o uso da distribuição de Poisson. 

Para resolver este problema, divida o intervalo de 4 horas em latexmath:[$n$] subintervalos, de mesmo tamanho, 
dado por latexmath:[$4/n$] horas, onde latexmath:[$n>500$]. Como 500 é o número médio de ligações recebidas
durante todo o período, é esperado que tenhamos no máximo uma ligação em cada intervalo (observe que se latexmath:[$n$] 
é muito grande, o intervalo fica muito pequeno, e a probabilidade de termos duas ligações no mesmo
intervalo é próxima de zero, assim essa aproximação faz sentido). 

Assim, temos aproximadamente uma probabilidade latexmath:[$500/n$] de termos uma ligação em cada intervalo. Como
temos latexmath:[$n$] intervalos, a probabilidade de termos latexmath:[$k$] ligações no total é dada pela 
probabilidade de escolhermos latexmath:[$k$] intervalos entre os latexmath:[$n$] intervalos disponíveis:
temos latexmath:[$n\choose k$] formas de escolher esses latexmath:[$k$] intervalos, e 
cada escolha dessas tem probabilidade latexmath:[$\Big(\frac{500}{n}\Big)^{k}\Big(1-\frac{500}{n}\Big)^{n-k}$].
Resumindo, se latexmath:[$X$] denota a variável aleatória cujo valor é o número de ligações
recebidas hoje durante as 4 horas, temos que latexmath:[$P(X=k)$], ou seja, 
a probabilidade de termos latexmath:[$k$] ligações é aproximadamente
[latexmath]
++++
\[P(X=k) \approx {n \choose k} \Big(\frac{500}{n}\Big)^{k}\Big(1-\frac{500}{n}\Big)^{n-k}.\]
++++
Em outras palavras, latexmath:[$X$] segue aproximadamente distribuição binomial latexmath:[$(n,500/n)$]. 
Observe que o valor esperado dessa aproximação binomial é dado por latexmath:[$500$], o que mostra que a
aproximação está consistente com o problema em questão.

Finalmente, para sabermos a probabilidade exata, temos que calcular o limite do lado direito quando
latexmath:[$n$] tende a infinito. Faremos isso na próxima subseção.
====

[NOTE] 
====
Vale a pena observar que calcular a probabilidade do exemplo anterior usando a aproximação acima sem 
calcular o limite é uma tarefa computacionalmente complicada, pois envolve cálculo de fatoriais de números
muito grandes. 

Por este motivo também, é muito comum usar uma aproximação inversa: se temos uma variável aleatória 
latexmath:[$X$] seguindo distribuição binomial com parâmetros latexmath:[$n$] e latexmath:[$p$], onde
latexmath:[$n$] é muito grande, é mais fácil calcular uma aproximação desta probabilidade usando a 
distribuição Poisson.
====

(((Distribuição, Poisson, Aproximação da Binomial)))

==== Aproximação da distribuição binomial pela Poisson

Baseado no exemplo da seção anterior, suponha que temos uma taxa média x:[\lambda>0],
e considere a sequência de variáveis aleatórias x:[X_1,X_2,\ldots,] onde 
cada x:[X_n] segue distribuição x:[Bin(n,\lambda/n)]. Observe que precisamos que 
x:[n] seja grande para que x:[\lambda/n<1] e portanto seja uma probabilidade.

Nosso objetivo nesta seção é calcular o limite
[latexmath]
++++
\[\lim_{n\to\infty} P(X_n=k) = \lim_{n\to\infty} {n\choose k} \Big(\frac{\lambda}{n}\Big)^k \Big(1-\frac{\lambda}{n}\Big)^{n-k}.\]
++++

[NOTE]
====
Para calcular o limite em questão, precisaremos relembrar alguns fatos básicos de cálculo
em uma variável. Relembre que o número de Euler, x:[e], é definido como
[latexmath]
++++
\[ e = \lim_{n\to\infty} \Big(1+\frac{1}{n}\Big)^n.\]
++++

Utilizando a regra de L'Hopital, podemos mostrar que para todo x:[x\in\mathbb{R}]
[latexmath]
++++
\[e^{x} = \lim_{n\to\infty} \Big(1+\frac{x}{n}\Big)^n.\]
++++

Desta forma, se tomarmos x:[x=-\lambda] na expressão acima, obtemos,

[latexmath]
++++
\[e^{-\lambda} = \lim_{n\to\infty} \Big(1-\frac{\lambda}{n}\Big)^n.\]
++++

Finalmente, para cada x:[k] natural fixado (constante, não muda com x:[n]), temos que
x:[\lim_{n\to\infty} \Big(1-\frac{\lambda}{n}\Big)^{k} = 1,] e portanto
[latexmath]
++++
\[\lim_{n\to\infty} \Big(1-\frac{\lambda}{n}\Big)^{n-k} = \lim_{n\to\infty} \frac{\Big(1-\frac{\lambda}{n}\Big)^n}{\Big(1-\frac{\lambda}{n}\Big)^k} = e^{-\lambda}.\]
++++
====

Para começarmos a calcular o limite, observe que para cada x:[k], temos
[latexmath]
++++
\[{n \choose k} = \frac{n!}{k!(n-k)!} = \frac{n(n-1)\cdots (n-k+1)}{k!}.\]
++++

Desta forma, temos
[latexmath]
++++
\[
\begin{array}{lll}
P(X_n = k) &=& \displaystyle {n\choose k} \Big(\frac{\lambda}{n}\Big)^k \Big(1-\frac{\lambda}{n}\Big)^{n-k}\\
&=& \displaystyle\frac{n(n-1)\cdots (n-k+1)}{k!} \Big(\frac{\lambda}{n}\Big)^k \Big(1-\frac{\lambda}{n}\Big)^{n-k}\\
&=& \displaystyle\frac{1}{k!} n(n-1)\cdots (n-k+1) \frac{\lambda^k}{n^k} \Big(1-\frac{\lambda}{n}\Big)^{n-k}\\
&=& \displaystyle\frac{\lambda^k}{k!} \frac{n(n-1)\cdots (n-k+1)}{n^k} \Big(1-\frac{\lambda}{n}\Big)^{n-k}\\
&=& \displaystyle\frac{\lambda^k}{k!} \frac{n}{n} \frac{n-1}{n} \cdots \frac{n-k+1}{n} \Big(1-\frac{\lambda}{n}\Big)^{n-k}\\
&=& \displaystyle\frac{\lambda^k}{k!} \Big( 1-\frac{1}{n}\Big) \cdots \Big( 1-\frac{(k-1)}{n}\Big) \Big(1-\frac{\lambda}{n}\Big)^{n-k}.
\end{array}
\]
++++

Temos que valem os seguintes limites:
[latexmath]
++++
\[\lim_{n\to\infty} \Big( 1-\frac{1}{n}\Big) \cdots \Big( 1-\frac{(k-1)}{n}\Big) = 1,\hbox{~~and~~}\quad
\lim_{n\to\infty} \Big(1-\frac{\lambda}{n}\Big)^{n-k} = e^{-\lambda}.
\]
++++

Portanto, obtemos
[latexmath]
++++
\[
\begin{array}{lll}
\displaystyle\lim_{n\to\infty} P(X_n = k) &=& \displaystyle\lim_{n\to\infty} \frac{\lambda^k}{k!} \Big( 1-\frac{1}{n}\Big) \cdots \Big( 1-\frac{(k-1)}{n}\Big) \Big(1-\frac{\lambda}{n}\Big)^{n-k}\\
&=& \displaystyle\frac{\lambda^k}{k!} e^{-\lambda}.
\end{array}
\]
++++

Este é o valor do limite procurado no final do exemplo, e assim, voltando ao exemplo:
.Motivação para a definição da distribuição Poisson
====
Relembremos que se latexmath:[$X$] denota a variável aleatória cujo valor é o número de ligações
recebidas hoje durante as 4 horas, temos que latexmath:[$P(X=k)$], ou seja, 
a probabilidade de termos latexmath:[$k$] ligações é aproximadamente
[latexmath]
++++
\[P(X=k) \approx {n \choose k} \Big(\frac{500}{n}\Big)^{k}\Big(1-\frac{500}{n}\Big)^{n-k}.\]
++++
Em outras palavras, latexmath:[$X$] segue aproximadamente distribuição binomial latexmath:[$(n,500/n)$]. 

O valor exato da probabilidade é então dado por
[latexmath]
++++
\[P(X=k) = \lim_{n\to\infty} {n \choose k} \Big(\frac{500}{n}\Big)^{k}\Big(1-\frac{500}{n}\Big)^{n-k} = \frac{500^k}{k!} e^{-500}.\]
++++

====

[IMPORTANT]
====
Este resultado de aproximação também pode ser usado para calcular aproximações de probabilidades
de distribuições binomiais quando x:[n] é muito grande.

Mais precisamente, se temos uma variável aleatória x:[X] seguindo distribuição binomial com
parâmetros x:[n] e x:[p], e x:[n] é muito grande, podemos aproximar esta probabilidade por
[latexmath]
++++
\[P(X=k) \approx \frac{(np)^k}{k!} e^{-np}.\]
++++
====


==== Distribuição Poisson

Definição: Variável Aleatória Seguindo Distribuição Poisson::
+
--
Suponha que temos ocorrências de eventos em um intervalo (de tempo ou espaço) latexmath:[$I$].
Suponha que temos um número médio de ocorrências em x:[I] é dado por latexmath:[$\lambda>0$],
e que a ocorrência de cada evento subsequente é independente da ocorrência dos eventos
anteriores. Então se latexmath:[$X$] denota o número de ocorrências do evento no intervalo x:[I],
dizemos que latexmath:[$X$] segue distribuição Poisson com parâmetro
latexmath:[$\lambda$], denotamos por latexmath:[$X\sim P(\lambda)$], e sua
função de probabilidade é dada por
[latexmath]
++++
\[
P(X=k) = \frac{\lambda^k}{k!}e^{-\lambda},\quad k=0,1,\ldots.
\]
++++
--

Para verificar que a função definida acima é realmente uma função de probabilidade, como temos,
claramente, que x:[\lambda^k/k! e^{-\lambda}>0], basta verificar que a soma sobre todos os
valores de x:[k] é igual a 1.

Para tanto, relembre a definição de função analítica. É um fato conhecido que a função
exponencial x:[f(x) = e^x] é analítica. Como temos que
[latexmath]
++++
\[
f(x) = e^x,\quad f'(x) = e^x,\quad f''(x) = e^x, \quad f'''(x) = e^x,
\]
++++
e, em geral, vale
[latexmath]
++++
\[
f^{(k)}(x) = e^x.
\]
++++
Portanto, aplicando em x:[a=0], temos que x:[f^{(k)}(0) = 1]. Assim, obtemos a série de Taylor da função
exponencial, 
[latexmath]
++++
\[
e^x = f(x) = \sum_{k=0}^\infty \frac{f^{(k)}(0)}{k!} x^k = \sum_{k=0}^\infty \frac{1}{k!}x^k.
\]
++++
Em particular, obtemos

[latexmath]
++++
\[
e^\lambda = \sum_{k=0}^\infty \frac{1}{k!}\lambda^k.
\]
++++

Vamos então mostrar que as probabilidades da Poisson formam, de fato, uma função de probabilidade:

[latexmath]
++++
\[
\begin{array}{lll}
\displaystyle\sum_{k=0}^\infty P(X=k) &=& \displaystyle\sum_{k=0}^\infty \frac{\lambda^k}{k!} e^{-\lambda}\\
&=& e^{-\lambda} \sum_{k=0}^\infty \frac{\lambda^k}{k!}\\
&=& e^{-\lambda} e^\lambda\\
&=& 1.
\end{array}
\]
++++


Esperança::
+
--
Temos que
[latexmath]
++++
\[
\begin{array}{lll}
E(X) &=& \sum_{k=0}^\infty k P(X=k)\\
&=& \sum_{k=0}^\infty k \frac{\lambda^k}{k!} e^{-\lambda}\\
&=& \sum_{k=1}^\infty k\frac{\lambda^k}{k!} e^{-\lambda}\\
&=& \sum_{k=1}^\infty \lambda\frac{\lambda^{k-1}}{(k-1)!} e^{-\lambda}\\
&=& \lambda \sum_{k=1}^\infty \frac{\lambda^{k-1}}{(k-1)!} e^{-\lambda}.
\end{array}
\]
++++
Fazendo x:[j=k-1], temos que
[latexmath]
++++
\[
\begin{array}{lll}
E(X) &=& \displaystyle\lambda \sum_{k=1}^\infty \frac{\lambda^{k-1}}{(k-1)!} e^{-\lambda}\\
&=& \displaystyle\lambda \sum_{j=0}^\infty \frac{\lambda^j}{j!} e^{-\lambda}\\
&=& \lambda e^\lambda e^{-\lambda}\\
&=& \lambda.
\end{array}
\]
++++

--


Variância::
+
--
Vamos começar calculando x:[E[X(X-1)\]]. Daí,
[latexmath]
++++
\[
\begin{array}{lll}
E[X(X-1)] &=& \displaystyle\sum_{k=0}^\infty k(k-1) P(X=k)\\
&=& \displaystyle\sum_{k=0}^\infty k(k-1) \frac{\lambda^k}{k!} e^{-\lambda}\\
&=& \displaystyle\sum_{k=2}^\infty k(k-1) \frac{\lambda^k}{k!} e^{-\lambda}\\
&=& \displaystyle\sum_{k=2}^\infty \frac{\lambda^k}{(k-2)!} e^{-\lambda}\\
&=& \displaystyle\sum_{k=2}^\infty \lambda^2\frac{\lambda^{k-2}}{(k-2)!} e^{-\lambda}.
\end{array}
\]
++++
Fazendo a mudança de variável x:[j=k-2], temos que
[latexmath]
++++
\[
\begin{array}{lll}
E[X(X-1)] &=& \displaystyle\sum_{k=2}^\infty \lambda^2\frac{\lambda^{k-2}}{(k-2)!} e^{-\lambda}\\
&=& \displaystyle\lambda^2\sum_{j=0}^\infty \frac{\lambda^j}{j!} e^{-\lambda}\\
&=& \lambda^2 e^\lambda e^{-\lambda}\\
&=& \lambda^2.
\end{array}
\]
++++
Porém, como temos que x:[E[X(X-1)\] = E(X^2) - E(X)], e portanto x:[E(X^2) = E[X(X-1)\] + E(X) = \lambda^2+\lambda].
Portanto, temos que
[latexmath]
++++
\[
Var(X) = E(X^2) - (EX)^2 = \lambda^2+\lambda - \lambda^2 = \lambda.
\]
++++

Desta forma, uma variável aleatória com distribuição Poisson com parâmetro x:[\lambda] possui esperança
e variância iguais a x:[\lambda].

--

